{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DEPRICATED - TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/21 23:56:35 INFO mlflow.tracking.fluent: Experiment with name 'escalation-detector-semantic-ml' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: /Users/mukeshsingh/Desktop/sumup\n",
            "Artifacts dir: /Users/mukeshsingh/Desktop/sumup/artifacts\n",
            "MLflow dir: /Users/mukeshsingh/Desktop/sumup/mlruns\n"
          ]
        }
      ],
      "source": [
        "import os, time, json, joblib, math, warnings, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# --- Repo paths ---\n",
        "NB_DIR = Path.cwd()\n",
        "REPO_ROOT = NB_DIR.parent  # assumes notebook lives in repo/notebooks/\n",
        "ARTIFACTS_DIR = Path(os.getenv(\"ARTIFACTS_DIR\", str(REPO_ROOT / \"artifacts\")))\n",
        "DATA_PARQUET = ARTIFACTS_DIR / \"turn_level_dataset.parquet\"\n",
        "DATA_CSV     = ARTIFACTS_DIR / \"turn_level_dataset.csv\"\n",
        "\n",
        "# Make src/ importable\n",
        "import sys\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "# MLflow\n",
        "import mlflow, mlflow.sklearn\n",
        "mlflow.set_tracking_uri(\"file:\" + str(REPO_ROOT / \"mlruns\"))\n",
        "mlflow.set_experiment(\"escalation-detector-semantic-ml\")\n",
        "\n",
        "print(\"Repo root:\", REPO_ROOT)\n",
        "print(\"Artifacts dir:\", ARTIFACTS_DIR)\n",
        "print(\"MLflow dir:\", REPO_ROOT / \"mlruns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: /Users/mukeshsingh/Desktop/sumup/artifacts/turn_level_dataset.parquet\n",
            "Shape: (61, 8) Conversations: 20 Pos rate: 0.197\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>turn_global_idx</th>\n",
              "      <th>user_turn_idx</th>\n",
              "      <th>user_text</th>\n",
              "      <th>prev_bot_text</th>\n",
              "      <th>y</th>\n",
              "      <th>y_reason</th>\n",
              "      <th>is_escalation_needed_convo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c001</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I have tried to verify id for another sum up a...</td>\n",
              "      <td>Hello there. If you’d like to return to your p...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c001</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>So I resent and haven’t heard anything back</td>\n",
              "      <td>Okay, it seems there might be an issue with th...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c001</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>It’s been 2 weeks</td>\n",
              "      <td>Okay, verification may take a couple of days. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>fallback_last_user</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c002</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I’m not being sent a code to verify my device ...</td>\n",
              "      <td>Hello there! I'm here to assist you with anyth...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c002</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>I’ve done that</td>\n",
              "      <td>**Didn't get the code?**\\n\\n1. Tap **Resend co...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c002</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes all of that is good</td>\n",
              "      <td>Okay, let's try another approach. Ensure your ...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c002</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>Where will I find that</td>\n",
              "      <td>Got it. As a next step, try enabling **Push no...</td>\n",
              "      <td>1</td>\n",
              "      <td>fallback_last_user</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>c003</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hi I'm having issues with reports since the re...</td>\n",
              "      <td>Hello! If you'd like to return to our previous...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  conversation_id  turn_global_idx  user_turn_idx  \\\n",
              "0            c001                1              0   \n",
              "1            c001                3              1   \n",
              "2            c001                5              2   \n",
              "3            c002                1              0   \n",
              "4            c002                3              1   \n",
              "5            c002                5              2   \n",
              "6            c002                7              3   \n",
              "7            c003                1              0   \n",
              "\n",
              "                                           user_text  \\\n",
              "0  I have tried to verify id for another sum up a...   \n",
              "1        So I resent and haven’t heard anything back   \n",
              "2                                  It’s been 2 weeks   \n",
              "3  I’m not being sent a code to verify my device ...   \n",
              "4                                     I’ve done that   \n",
              "5                            Yes all of that is good   \n",
              "6                             Where will I find that   \n",
              "7  Hi I'm having issues with reports since the re...   \n",
              "\n",
              "                                       prev_bot_text  y            y_reason  \\\n",
              "0  Hello there. If you’d like to return to your p...  0                       \n",
              "1  Okay, it seems there might be an issue with th...  0                       \n",
              "2  Okay, verification may take a couple of days. ...  1  fallback_last_user   \n",
              "3  Hello there! I'm here to assist you with anyth...  0                       \n",
              "4  **Didn't get the code?**\\n\\n1. Tap **Resend co...  0                       \n",
              "5  Okay, let's try another approach. Ensure your ...  0                       \n",
              "6  Got it. As a next step, try enabling **Push no...  1  fallback_last_user   \n",
              "7  Hello! If you'd like to return to our previous...  0                       \n",
              "\n",
              "   is_escalation_needed_convo  \n",
              "0                           1  \n",
              "1                           1  \n",
              "2                           1  \n",
              "3                           1  \n",
              "4                           1  \n",
              "5                           1  \n",
              "6                           1  \n",
              "7                           1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "EXPECTED_COLS = {\n",
        "    \"conversation_id\", \"turn_global_idx\", \"user_turn_idx\",\n",
        "    \"user_text\", \"prev_bot_text\", \"y\", \"is_escalation_needed_convo\"\n",
        "}\n",
        "\n",
        "def load_turn_dataset():\n",
        "    if DATA_PARQUET.exists():\n",
        "        df = pd.read_parquet(DATA_PARQUET)\n",
        "        src = DATA_PARQUET\n",
        "    elif DATA_CSV.exists():\n",
        "        df = pd.read_csv(DATA_CSV)\n",
        "        src = DATA_CSV\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Turn-level dataset not found. Expected {DATA_PARQUET} or {DATA_CSV}.\"\n",
        "        )\n",
        "    missing = EXPECTED_COLS - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Dataset is missing expected columns: {missing}\")\n",
        "    # Normalize dtypes\n",
        "    df = df.copy()\n",
        "    df[\"conversation_id\"] = df[\"conversation_id\"].astype(\"string\")\n",
        "    df[\"turn_global_idx\"] = df[\"turn_global_idx\"].astype(\"int32\")\n",
        "    df[\"user_turn_idx\"] = df[\"user_turn_idx\"].astype(\"int32\")\n",
        "    df[\"user_text\"] = df[\"user_text\"].astype(\"string\")\n",
        "    df[\"prev_bot_text\"] = df[\"prev_bot_text\"].astype(\"string\")\n",
        "    df[\"y\"] = df[\"y\"].astype(\"int8\")\n",
        "    df[\"is_escalation_needed_convo\"] = df[\"is_escalation_needed_convo\"].astype(\"int8\")\n",
        "    print(\"Loaded:\", src)\n",
        "    return df\n",
        "\n",
        "df = load_turn_dataset()\n",
        "print(\"Shape:\", df.shape, \"Conversations:\", df[\"conversation_id\"].nunique(), \"Pos rate:\", round(float(df[\"y\"].mean()),3))\n",
        "display(df.head(8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy version: policy@prod-1\n",
            "Semantic embeddings: OK\n"
          ]
        }
      ],
      "source": [
        "# Load policy (repo root preferred) or fallback to minimal defaults.\n",
        "import yaml\n",
        "\n",
        "def load_policy():\n",
        "    repo_policy = REPO_ROOT / \"policy.yaml\"\n",
        "    art_policy  = ARTIFACTS_DIR / \"policy.yaml\"\n",
        "    if repo_policy.exists():\n",
        "        with open(repo_policy, \"r\", encoding=\"utf-8\") as f:\n",
        "            return yaml.safe_load(f) or {}\n",
        "    elif art_policy.exists():\n",
        "        with open(art_policy, \"r\", encoding=\"utf-8\") as f:\n",
        "            return yaml.safe_load(f) or {}\n",
        "    else:\n",
        "        # Minimal defaults (rules for risk & explicit human)\n",
        "        return {\n",
        "            \"version\": \"policy@notebook-default\",\n",
        "            \"guards\": {\"min_turn_before_model\": 1},\n",
        "            \"rules\": {\n",
        "                \"explicit_human_request\": {\n",
        "                    \"enabled\": True,\n",
        "                    \"patterns\": [r\"\\b(human|agent|real person|talk to (?:a )?human|speak to (?:a )?human|customer service|support agent)\\b\"]\n",
        "                },\n",
        "                \"risk_terms\": {\"enabled\": True, \"patterns\": [\"kyc\",\"blocked\",\"chargeback\",\"legal\",\"id verification\"]},\n",
        "                \"bot_unhelpful_templates\": {\"enabled\": True, \"patterns\": [\n",
        "                    \"could you provide more details\",\"we could not find the information\",\"check your spam folder\",\n",
        "                    \"ensure your documents are clear and valid\"\n",
        "                ]}\n",
        "            }\n",
        "        }\n",
        "\n",
        "policy = load_policy()\n",
        "print(\"Policy version:\", policy.get(\"version\"))\n",
        "\n",
        "# Optional warm-up of the semantic detector (if sentence-transformers is available).\n",
        "# Training continues even if embeddings aren't available; features fall back to zeros.\n",
        "try:\n",
        "    from src.semantic_detection import get_semantic_detector\n",
        "    _ = get_semantic_detector()\n",
        "    print(\"Semantic embeddings: OK\")\n",
        "except Exception as e:\n",
        "    print(\"Semantic embeddings unavailable, proceeding with zeros:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_all shape: (61, 12) y mean: 0.197\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>turn_idx</th>\n",
              "      <th>user_caps_ratio</th>\n",
              "      <th>exclam_count</th>\n",
              "      <th>msg_len</th>\n",
              "      <th>bot_unhelpful</th>\n",
              "      <th>user_requests_human</th>\n",
              "      <th>risk_terms</th>\n",
              "      <th>no_progress_count</th>\n",
              "      <th>bot_repeat_count</th>\n",
              "      <th>semantic_frustration_score</th>\n",
              "      <th>semantic_unhelpful_score</th>\n",
              "      <th>semantic_human_request_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260941</td>\n",
              "      <td>0.188849</td>\n",
              "      <td>0.170362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187796</td>\n",
              "      <td>0.156374</td>\n",
              "      <td>0.150503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.440087</td>\n",
              "      <td>0.224596</td>\n",
              "      <td>0.111789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.269645</td>\n",
              "      <td>0.357625</td>\n",
              "      <td>0.175918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.487891</td>\n",
              "      <td>0.261046</td>\n",
              "      <td>0.120573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117935</td>\n",
              "      <td>0.104550</td>\n",
              "      <td>0.075511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263050</td>\n",
              "      <td>0.120984</td>\n",
              "      <td>0.193333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.162414</td>\n",
              "      <td>0.160482</td>\n",
              "      <td>0.084144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   turn_idx  user_caps_ratio  exclam_count  msg_len  bot_unhelpful  \\\n",
              "0       0.0         0.030303           0.0    250.0            0.0   \n",
              "1       1.0         0.057143           0.0     43.0            0.0   \n",
              "2       2.0         0.083333           0.0     17.0            1.0   \n",
              "3       0.0         0.038462           0.0     99.0            0.0   \n",
              "4       1.0         0.090909           0.0     14.0            0.0   \n",
              "5       2.0         0.055556           0.0     23.0            0.0   \n",
              "6       3.0         0.111111           0.0     22.0            0.0   \n",
              "7       0.0         0.027027           0.0     89.0            0.0   \n",
              "\n",
              "   user_requests_human  risk_terms  no_progress_count  bot_repeat_count  \\\n",
              "0                  0.0         0.0                0.0               0.0   \n",
              "1                  0.0         0.0                0.0               0.0   \n",
              "2                  0.0         0.0                0.0               0.0   \n",
              "3                  0.0         0.0                0.0               0.0   \n",
              "4                  0.0         0.0                0.0               0.0   \n",
              "5                  0.0         0.0                0.0               0.0   \n",
              "6                  0.0         0.0                0.0               0.0   \n",
              "7                  0.0         0.0                0.0               0.0   \n",
              "\n",
              "   semantic_frustration_score  semantic_unhelpful_score  \\\n",
              "0                    0.260941                  0.188849   \n",
              "1                    0.187796                  0.156374   \n",
              "2                    0.440087                  0.224596   \n",
              "3                    0.269645                  0.357625   \n",
              "4                    0.487891                  0.261046   \n",
              "5                    0.117935                  0.104550   \n",
              "6                    0.263050                  0.120984   \n",
              "7                    0.162414                  0.160482   \n",
              "\n",
              "   semantic_human_request_score  \n",
              "0                      0.170362  \n",
              "1                      0.150503  \n",
              "2                      0.111789  \n",
              "3                      0.175918  \n",
              "4                      0.120573  \n",
              "5                      0.075511  \n",
              "6                      0.193333  \n",
              "7                      0.084144  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from src.features import featurize_one\n",
        "\n",
        "# Single source of truth for features used both in training & serving.\n",
        "FEATURE_ORDER = [\n",
        "  \"turn_idx\",\n",
        "  \"user_caps_ratio\",\n",
        "  \"exclam_count\",\n",
        "  \"msg_len\",\n",
        "  \"bot_unhelpful\",\n",
        "  \"user_requests_human\",\n",
        "  \"risk_terms\",\n",
        "  \"no_progress_count\",\n",
        "  \"bot_repeat_count\",\n",
        "  \"semantic_frustration_score\",\n",
        "  \"semantic_unhelpful_score\",\n",
        "  \"semantic_human_request_score\",\n",
        "]\n",
        "\n",
        "def build_design_matrix(df_in: pd.DataFrame, policy: dict) -> (pd.DataFrame, np.ndarray, pd.DataFrame):\n",
        "    rows = []\n",
        "    # We'll also rebuild a df_meta for grouped metrics\n",
        "    meta = df_in[[\"conversation_id\",\"user_turn_idx\",\"y\"]].reset_index(drop=True).copy()\n",
        "    # rolling state per conversation must be reset\n",
        "    for cid, block in df_in.groupby(\"conversation_id\", sort=False):\n",
        "        state = {\"user_turn_idx\": 0, \"no_progress_count\": 0.0, \"bot_repeat_count\": 0.0, \"prev_bot_text\": \"\"}\n",
        "        block_sorted = block.sort_values([\"user_turn_idx\",\"turn_global_idx\"])\n",
        "        for _, r in block_sorted.iterrows():\n",
        "            # user turn index must reflect position, not raw value from file (to mirror runtime counter)\n",
        "            user_idx = int(state.get(\"user_turn_idx\", 0))\n",
        "            row_df, state = featurize_one(user_idx, str(r[\"user_text\"]), str(r[\"prev_bot_text\"]), state, policy, FEATURE_ORDER)\n",
        "            rows.append(row_df.values[0])\n",
        "            # increment when we actually consumed a user message\n",
        "            state[\"user_turn_idx\"] = user_idx + 1\n",
        "    X = pd.DataFrame(rows, columns=FEATURE_ORDER)\n",
        "    y = df_in[\"y\"].astype(int).values\n",
        "    return X, y, meta\n",
        "\n",
        "X_all, y_all, meta_all = build_design_matrix(df, policy)\n",
        "print(\"X_all shape:\", X_all.shape, \"y mean:\", round(float(y_all.mean()),3))\n",
        "display(X_all.head(8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "\n",
        "def early_escalation_at_first(df_meta: pd.DataFrame, y_true: np.ndarray, proba: np.ndarray, tau: float) -> float:\n",
        "    tmp = df_meta.copy()\n",
        "    tmp[\"proba\"] = proba\n",
        "    tmp[\"pred\"] = (proba >= tau).astype(int)\n",
        "    good = 0\n",
        "    total_pos = 0\n",
        "    for cid, block in tmp.groupby(\"conversation_id\"):\n",
        "        block = block.sort_values(\"user_turn_idx\")\n",
        "        if block[\"y\"].max() == 0:\n",
        "            continue\n",
        "        total_pos += 1\n",
        "        first_pos = int(block[block[\"y\"] == 1][\"user_turn_idx\"].min())\n",
        "        pred_before_or_at = block[block[\"user_turn_idx\"] <= first_pos][\"pred\"]\n",
        "        fired_before_or_at = int(pred_before_or_at.max()) == 1 if len(pred_before_or_at) > 0 else False\n",
        "        if fired_before_or_at:\n",
        "            good += 1\n",
        "    return (good / total_pos) if total_pos else np.nan\n",
        "\n",
        "def premature_posconv(df_meta: pd.DataFrame, y_true: np.ndarray, proba: np.ndarray, tau: float) -> float:\n",
        "    # Fraction of positive conversations where we escalate before the first positive label\n",
        "    tmp = df_meta.copy()\n",
        "    tmp[\"proba\"] = proba\n",
        "    tmp[\"pred\"] = (proba >= tau).astype(int)\n",
        "    bad = 0\n",
        "    total_pos = 0\n",
        "    for cid, block in tmp.groupby(\"conversation_id\"):\n",
        "        block = block.sort_values(\"user_turn_idx\")\n",
        "        if block[\"y\"].max() == 0:\n",
        "            continue\n",
        "        total_pos += 1\n",
        "        first_pos = int(block[block[\"y\"] == 1][\"user_turn_idx\"].min())\n",
        "        pred_before = block[block[\"user_turn_idx\"] < first_pos][\"pred\"]\n",
        "        fired_before = int(pred_before.max()) == 1 if len(pred_before) > 0 else False\n",
        "        if fired_before:\n",
        "            bad += 1\n",
        "    return (bad / total_pos) if total_pos else np.nan\n",
        "\n",
        "def false_alarm_negconv(df_meta: pd.DataFrame, y_true: np.ndarray, proba: np.ndarray, tau: float) -> float:\n",
        "    # Fraction of negative conversations where we ever escalate\n",
        "    tmp = df_meta.copy()\n",
        "    tmp[\"proba\"] = proba\n",
        "    tmp[\"pred\"] = (proba >= tau).astype(int)\n",
        "    neg_total, neg_bad = 0, 0\n",
        "    for cid, block in tmp.groupby(\"conversation_id\"):\n",
        "        block = block.sort_values(\"user_turn_idx\")\n",
        "        if block[\"y\"].max() == 1:\n",
        "            continue\n",
        "        neg_total += 1\n",
        "        if block[\"pred\"].max() == 1:\n",
        "            neg_bad += 1\n",
        "    return (neg_bad / neg_total) if neg_total else np.nan\n",
        "\n",
        "def tte_mean(df_meta: pd.DataFrame, y_true: np.ndarray, proba: np.ndarray, tau: float) -> float:\n",
        "    # Time-to-escalation relative to first positive user turn; negative if after, positive if before\n",
        "    tmp = df_meta.copy()\n",
        "    tmp[\"proba\"] = proba\n",
        "    tmp[\"pred\"] = (proba >= tau).astype(int)\n",
        "    vals = []\n",
        "    for cid, block in tmp.groupby(\"conversation_id\"):\n",
        "        block = block.sort_values(\"user_turn_idx\")\n",
        "        if block[\"y\"].max() == 0:\n",
        "            continue\n",
        "        first_pos = int(block[block[\"y\"] == 1][\"user_turn_idx\"].min())\n",
        "        fired_idxs = block[block[\"pred\"] == 1][\"user_turn_idx\"]\n",
        "        if not fired_idxs.empty:\n",
        "            first_fire = int(fired_idxs.min())\n",
        "            vals.append(first_fire - first_pos)\n",
        "    return float(np.mean(vals)) if vals else np.nan\n",
        "\n",
        "def eval_at_tau(df_meta, y_true, proba, tau):\n",
        "    return {\n",
        "        \"roc_auc\": roc_auc_score(y_true, proba),\n",
        "        \"pr_auc\":  average_precision_score(y_true, proba),\n",
        "        \"early_at_first\": early_escalation_at_first(df_meta, y_true, proba, tau),\n",
        "        \"premature_posconv\": premature_posconv(df_meta, y_true, proba, tau),\n",
        "        \"false_alarm_negconv\": false_alarm_negconv(df_meta, y_true, proba, tau),\n",
        "        \"tte_mean\": tte_mean(df_meta, y_true, proba, tau),\n",
        "        \"tau\": float(tau)\n",
        "    }\n",
        "\n",
        "def choose_tau_constrained(df_meta, y_true, proba, cap_premature=0.20):\n",
        "    grid = np.linspace(0.01, 0.99, 99)\n",
        "    rows = []\n",
        "    best_tau, best_key = None, (-math.inf, )\n",
        "    for tau in grid:\n",
        "        m = eval_at_tau(df_meta, y_true, proba, tau)\n",
        "        if m[\"premature_posconv\"] is not np.nan and (m[\"premature_posconv\"] is not None):\n",
        "            if (not np.isnan(m[\"premature_posconv\"])) and (m[\"premature_posconv\"] <= cap_premature):\n",
        "                key = (m[\"early_at_first\"], m[\"pr_auc\"], m[\"roc_auc\"])\n",
        "                if best_tau is None or (np.nan_to_num(key, nan=-1e9) > np.nan_to_num(best_key, nan=-1e9)).any():\n",
        "                    best_tau, best_key = tau, key\n",
        "        rows.append(m)\n",
        "    table = pd.DataFrame(rows)\n",
        "    if best_tau is None:\n",
        "        # fallback: pick F1-like\n",
        "        prec, rec, thr = precision_recall_curve(y_true, proba)\n",
        "        f1 = (2 * prec * rec) / (prec + rec + 1e-9)\n",
        "        idx = int(np.nanargmax(f1))\n",
        "        best_tau = float(thr[max(0, idx - 1)]) if len(thr) else 0.5\n",
        "    return float(best_tau), table.sort_values(\"tau\").reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:00:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[logreg_calibrated] ROC-AUC=0.683 PR-AUC=0.594 early@first=0.500 premature=0.000 Fneg=0.500 tau=0.460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:00:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[histgb] ROC-AUC=0.500 PR-AUC=0.211 early@first=0.000 premature=0.000 Fneg=0.000 tau=0.220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:00:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[random_forest] ROC-AUC=0.700 PR-AUC=0.537 early@first=0.250 premature=0.000 Fneg=0.000 tau=0.510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:00:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[xgboost] ROC-AUC=0.425 PR-AUC=0.287 early@first=0.000 premature=0.000 Fneg=0.000 tau=0.500\n",
            "\n",
            "Best by (early@first, PR, ROC): logreg_calibrated tau_base: 0.46\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>tau</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>pr_auc</th>\n",
              "      <th>early_at_first</th>\n",
              "      <th>premature_posconv</th>\n",
              "      <th>false_alarm_negconv</th>\n",
              "      <th>tte_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logreg_calibrated</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>random_forest</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.287007</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>histgb</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               model   tau   roc_auc    pr_auc  early_at_first  \\\n",
              "0  logreg_calibrated  0.46  0.683333  0.594298            0.50   \n",
              "2      random_forest  0.51  0.700000  0.537500            0.25   \n",
              "3            xgboost  0.50  0.425000  0.287007            0.00   \n",
              "1             histgb  0.22  0.500000  0.210526            0.00   \n",
              "\n",
              "   premature_posconv  false_alarm_negconv  tte_mean  \n",
              "0                0.0                  0.5       0.0  \n",
              "2                0.0                  0.0       0.0  \n",
              "3                0.0                  0.0       NaN  \n",
              "1                0.0                  0.0       NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# optional xgboost (we fail closed if not available)\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGB_OK = True\n",
        "except Exception:\n",
        "    XGB_OK = False\n",
        "\n",
        "def train_eval_log(name, estimator, Xtr, ytr, Xte, yte, df_te, calibrate=True, params=None):\n",
        "    params = params or {}\n",
        "    run_name = f\"{name}_{int(time.time())}\"\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        # estimator params\n",
        "        try:\n",
        "            est_params = estimator.get_params(deep=False)\n",
        "        except Exception:\n",
        "            est_params = {}\n",
        "        mlflow.log_params({\"model\": name, **est_params, **params})\n",
        "\n",
        "        # fit + calibrate\n",
        "        if calibrate:\n",
        "            try:\n",
        "                clf = CalibratedClassifierCV(estimator, cv=3, method=\"sigmoid\")\n",
        "                clf.fit(Xtr, ytr)\n",
        "            except Exception as e:\n",
        "                # fallback to prefit\n",
        "                estimator.fit(Xtr, ytr)\n",
        "                clf = CalibratedClassifierCV(estimator, cv=\"prefit\", method=\"sigmoid\")\n",
        "                clf.fit(Xtr, ytr)\n",
        "        else:\n",
        "            estimator.fit(Xtr, ytr)\n",
        "            clf = estimator\n",
        "\n",
        "        proba = clf.predict_proba(Xte)[:,1]\n",
        "        roc = roc_auc_score(yte, proba)\n",
        "        pr  = average_precision_score(yte, proba)\n",
        "        tau_base, table = choose_tau_constrained(df_te, yte, proba, cap_premature=0.20)\n",
        "        m = eval_at_tau(df_te, yte, proba, tau_base)\n",
        "\n",
        "        # log metrics\n",
        "        mlflow.log_metrics({\n",
        "            \"roc_auc\": float(roc),\n",
        "            \"pr_auc\": float(pr),\n",
        "            \"tau_base\": float(tau_base),\n",
        "            \"early_at_first\": float(m[\"early_at_first\"]),\n",
        "            \"premature_posconv\": float(m[\"premature_posconv\"]),\n",
        "            \"false_alarm_negconv\": float(m[\"false_alarm_negconv\"]),\n",
        "            \"tte_mean\": float(m[\"tte_mean\"]),\n",
        "        })\n",
        "\n",
        "        # signature + input example\n",
        "        try:\n",
        "            from mlflow.models.signature import infer_signature\n",
        "            sig = infer_signature(Xtr, clf.predict_proba(Xtr)[:,1])\n",
        "            mlflow.sklearn.log_model(clf, artifact_path=\"model\", signature=sig, input_example=Xtr.head(5))\n",
        "        except Exception:\n",
        "            mlflow.sklearn.log_model(clf, artifact_path=\"model\")\n",
        "\n",
        "        print(f\"[{name}] ROC-AUC={roc:.3f} PR-AUC={pr:.3f} early@first={m['early_at_first']:.3f} \"\n",
        "              f\"premature={m['premature_posconv']:.3f} Fneg={m['false_alarm_negconv']:.3f} tau={tau_base:.3f}\")\n",
        "\n",
        "        return clf, tau_base, m, table\n",
        "\n",
        "candidates = []\n",
        "candidates.append((\"logreg_calibrated\",\n",
        "                   LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
        "                   True,\n",
        "                   {\"notes\":\"interpretable baseline\"}))\n",
        "candidates.append((\"histgb\",\n",
        "                   HistGradientBoostingClassifier(random_state=42, learning_rate=0.12, max_depth=None),\n",
        "                   True,\n",
        "                   {\"notes\":\"tree boosting\"}))\n",
        "candidates.append((\"random_forest\",\n",
        "                   RandomForestClassifier(n_estimators=400, max_depth=None, class_weight=\"balanced_subsample\", n_jobs=-1, random_state=42),\n",
        "                   True,\n",
        "                   {\"notes\":\"rf baseline\"}))\n",
        "if XGB_OK:\n",
        "    candidates.append((\"xgboost\",\n",
        "                       xgb.XGBClassifier(n_estimators=500, max_depth=5, learning_rate=0.06, subsample=0.9, colsample_bytree=0.9,\n",
        "                                         reg_lambda=1.0, objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\",\n",
        "                                         n_jobs=-1, random_state=42),\n",
        "                       True,\n",
        "                       {\"notes\":\"xgb strong tabular\"}))\n",
        "else:\n",
        "    print(\"XGBoost not available; skipping.\")\n",
        "\n",
        "results = []\n",
        "best = None\n",
        "best_key = None\n",
        "\n",
        "for name, est, calibrate, params in candidates:\n",
        "    clf, tau_b, metrics, table = train_eval_log(name, est, X_train, y_train, X_test, y_test, df_test, calibrate, params)\n",
        "    results.append({\"model\": name, \"tau\": tau_b, **metrics})\n",
        "    key = (metrics[\"early_at_first\"], metrics[\"pr_auc\"], metrics[\"roc_auc\"])\n",
        "    if best is None:\n",
        "        best = (clf, tau_b, name, metrics, table)\n",
        "        best_key = key\n",
        "    else:\n",
        "        # prioritize early@first, break ties with PR-AUC then ROC\n",
        "        if key > best_key or (np.isnan(best_key[0]) and not np.isnan(key[0])):\n",
        "            best, best_key = (clf, tau_b, name, metrics, table), key\n",
        "\n",
        "print(\"\\nBest by (early@first, PR, ROC):\", best[2], \"tau_base:\", round(best[1],3))\n",
        "df_results = pd.DataFrame(results).sort_values([\"early_at_first\",\"pr_auc\",\"roc_auc\"], ascending=[False,False,False])\n",
        "display(df_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported:\n",
            " - /Users/mukeshsingh/Desktop/sumup/artifacts/model.joblib\n",
            " - /Users/mukeshsingh/Desktop/sumup/artifacts/feature_order.json\n",
            " - /Users/mukeshsingh/Desktop/sumup/artifacts/version.txt\n",
            " - /Users/mukeshsingh/Desktop/sumup/artifacts/policy.yaml\n",
            "Chosen tau_base=0.460  early@first=0.500  premature=0.000  false_alarm=0.500  tte_mean=0.000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>pr_auc</th>\n",
              "      <th>early_at_first</th>\n",
              "      <th>premature_posconv</th>\n",
              "      <th>false_alarm_negconv</th>\n",
              "      <th>tte_mean</th>\n",
              "      <th>tau</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.333333</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.333333</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.333333</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    roc_auc    pr_auc  early_at_first  premature_posconv  false_alarm_negconv  \\\n",
              "0  0.683333  0.594298            1.00               0.75                  1.0   \n",
              "1  0.683333  0.594298            1.00               0.75                  1.0   \n",
              "2  0.683333  0.594298            1.00               0.75                  1.0   \n",
              "3  0.683333  0.594298            1.00               0.75                  1.0   \n",
              "4  0.683333  0.594298            0.75               0.75                  1.0   \n",
              "5  0.683333  0.594298            0.75               0.75                  1.0   \n",
              "6  0.683333  0.594298            0.75               0.75                  1.0   \n",
              "7  0.683333  0.594298            0.75               0.75                  1.0   \n",
              "8  0.683333  0.594298            0.75               0.75                  1.0   \n",
              "9  0.683333  0.594298            0.75               0.75                  0.5   \n",
              "\n",
              "   tte_mean   tau  \n",
              "0 -2.500000  0.01  \n",
              "1 -2.500000  0.02  \n",
              "2 -2.500000  0.03  \n",
              "3 -2.500000  0.04  \n",
              "4 -3.333333  0.05  \n",
              "5 -3.333333  0.06  \n",
              "6 -3.333333  0.07  \n",
              "7 -3.000000  0.08  \n",
              "8 -3.000000  0.09  \n",
              "9 -2.000000  0.10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_clf, tau_base, best_name, best_metrics, best_table = best\n",
        "\n",
        "# Suggest tau_high: instant escalate for very confident cases\n",
        "tau_hi = float(np.clip(max(np.quantile(best_table[\"tau\"].values, 0.95), tau_base + 0.20), 0.50, 0.99))\n",
        "\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "model_path = ARTIFACTS_DIR / \"model.joblib\"\n",
        "joblib.dump(best_clf, model_path)\n",
        "\n",
        "# Save feature order\n",
        "feat_path = ARTIFACTS_DIR / \"feature_order.json\"\n",
        "with open(feat_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(FEATURE_ORDER, f, indent=2)\n",
        "\n",
        "# Build version file\n",
        "version_txt = ARTIFACTS_DIR / \"version.txt\"\n",
        "now = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime())\n",
        "with open(version_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"model_type={best_name}\\n\")\n",
        "    f.write(f\"training_date={now}\\n\")\n",
        "    f.write(f\"features={len(FEATURE_ORDER)}\\n\")\n",
        "    f.write(f\"test_auc={best_metrics['roc_auc']:.3f}\\n\")\n",
        "    f.write(f\"pr_auc={best_metrics['pr_auc']:.3f}\\n\")\n",
        "    f.write(f\"threshold={tau_base}\\n\")\n",
        "    f.write(f\"tau_high={tau_hi}\\n\")\n",
        "\n",
        "# Write policy snapshot specific to artifacts (does not overwrite repo policy.yaml)\n",
        "policy_snapshot = {\n",
        "    \"version\": f\"policy@snapshot:{now}\",\n",
        "    \"thresholds\": {\n",
        "        \"tau_low\": float(tau_base),\n",
        "        \"tau_high\": float(tau_hi)\n",
        "    },\n",
        "    \"guards\": {\n",
        "        \"min_turn_before_model\": int((policy.get(\"guards\") or {}).get(\"min_turn_before_model\", 1))\n",
        "    },\n",
        "    \"rules\": (policy.get(\"rules\") or {})\n",
        "}\n",
        "with open(ARTIFACTS_DIR / \"policy.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    import yaml\n",
        "    yaml.safe_dump(policy_snapshot, f, sort_keys=False)\n",
        "\n",
        "print(\"Exported:\")\n",
        "print(\" -\", model_path)\n",
        "print(\" -\", feat_path)\n",
        "print(\" -\", version_txt)\n",
        "print(\" -\", ARTIFACTS_DIR / \"policy.yaml\")\n",
        "\n",
        "# Show a slice of the threshold table around tau_base\n",
        "nearest = best_table.iloc[(best_table[\"tau\"] - tau_base).abs().argmin()]\n",
        "print(f\"Chosen tau_base={tau_base:.3f}  early@first={nearest['early_at_first']:.3f}  \"\n",
        "      f\"premature={nearest['premature_posconv']:.3f}  false_alarm={nearest['false_alarm_negconv']:.3f}  \"\n",
        "      f\"tte_mean={nearest['tte_mean']:.3f}\")\n",
        "display(best_table.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloaded tau: 0.46\n",
            "RELOAD TEST — ROC-AUC=0.683 PR-AUC=0.594 early@first=0.500 premature=0.000 false_alarm=0.500 tte_mean=0.000 tau=0.460\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>user_turn_idx</th>\n",
              "      <th>y</th>\n",
              "      <th>proba</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.374504</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c001</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.105293</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c001</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.496187</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.099181</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c002</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.078037</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c002</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.161261</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c002</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.277314</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>c006</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.077110</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>c006</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.091090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>c006</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.160898</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  conversation_id  user_turn_idx  y     proba  pred\n",
              "0            c001              0  0  0.374504     0\n",
              "1            c001              1  0  0.105293     0\n",
              "2            c001              2  1  0.496187     1\n",
              "3            c002              0  0  0.099181     0\n",
              "4            c002              1  0  0.078037     0\n",
              "5            c002              2  0  0.161261     0\n",
              "6            c002              3  1  0.277314     0\n",
              "7            c006              0  0  0.077110     0\n",
              "8            c006              1  0  0.091090     0\n",
              "9            c006              2  0  0.160898     0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Ensure we reload using the same API as your service uses\n",
        "from src.model import load_artifacts\n",
        "\n",
        "mdl, feat_order_reload, tau_loaded, pol = load_artifacts(str(ARTIFACTS_DIR))\n",
        "print(\"Reloaded tau:\", tau_loaded)\n",
        "# Align columns to the artifact's feature order (serving will use this order)\n",
        "X_test_aligned = X_test.reindex(columns=feat_order_reload)\n",
        "\n",
        "proba_reload = mdl.predict_proba(X_test_aligned)[:,1]\n",
        "m_reload = eval_at_tau(df_test, y_test, proba_reload, tau_loaded)\n",
        "\n",
        "print(f\"RELOAD TEST — ROC-AUC={m_reload['roc_auc']:.3f} PR-AUC={m_reload['pr_auc']:.3f} \"\n",
        "      f\"early@first={m_reload['early_at_first']:.3f} premature={m_reload['premature_posconv']:.3f} \"\n",
        "      f\"false_alarm={m_reload['false_alarm_negconv']:.3f} tte_mean={m_reload['tte_mean']:.3f} tau={tau_loaded:.3f}\")\n",
        "\n",
        "display(pd.DataFrame({\n",
        "    \"conversation_id\": df_test[\"conversation_id\"].values[:10],\n",
        "    \"user_turn_idx\": df_test[\"user_turn_idx\"].values[:10],\n",
        "    \"y\": df_test[\"y\"].values[:10],\n",
        "    \"proba\": proba_reload[:10],\n",
        "    \"pred\": (proba_reload[:10] >= tau_loaded).astype(int)\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
