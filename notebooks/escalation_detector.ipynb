{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:18:35 INFO mlflow.tracking.fluent: Experiment with name 'escalation-detector-e2e' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using SEED: 42\n",
            "Data path: ../data/escalation_dataset.json\n",
            "Artifacts dir: artifacts\n",
            "MLruns dir: ./mlruns\n",
            "Policy path: policy.yaml\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === Config & imports ===\n",
        "import os, re, time, json, joblib, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "# Reproducibility\n",
        "SEED = int(os.getenv(\"SEED\", \"42\"))\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "# Paths\n",
        "DATA_PATH = os.getenv(\"CONV_PATH\", \"../data/escalation_dataset.json\")\n",
        "ARTIFACTS_DIR = os.getenv(\"ARTIFACTS_DIR\", \"artifacts\")\n",
        "MLRUNS_DIR = os.getenv(\"MLRUNS_DIR\", \"./mlruns\")\n",
        "POLICY_PATH = os.getenv(\"POLICY_PATH\", \"policy.yaml\")\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "\n",
        "# MLflow\n",
        "import mlflow, mlflow.sklearn\n",
        "mlflow.set_tracking_uri(f\"file:{MLRUNS_DIR}\")\n",
        "mlflow.set_experiment(\"escalation-detector-e2e\")\n",
        "\n",
        "print(\"Using SEED:\", SEED)\n",
        "print(\"Data path:\", DATA_PATH)\n",
        "print(\"Artifacts dir:\", ARTIFACTS_DIR)\n",
        "print(\"MLruns dir:\", MLRUNS_DIR)\n",
        "print(\"Policy path:\", POLICY_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "policy.yaml not found at policy.yaml; using defaults and writing snapshot to artifacts.\n",
            "Policy loaded. Explicit patterns: ['\\\\b(human|agent|real person|talk to (?:a )?human|speak to (?:a )?human|customer service|support agent)\\\\b'] ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === Load policy (regex patterns). If policy.yaml missing, use defaults and snapshot. ===\n",
        "try:\n",
        "    import yaml\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"pyyaml is required: pip install pyyaml\") from e\n",
        "\n",
        "DEFAULT_POLICY = {\n",
        "    \"version\": \"policy@notebook\",\n",
        "    \"thresholds\": {\"tau_low\": 0.45, \"tau_high\": 0.70},\n",
        "    \"rules\": {\n",
        "        \"explicit_human_request\": {\n",
        "            \"enabled\": True,\n",
        "            \"patterns\": [r\"\\b(human|agent|real person|talk to (?:a )?human|speak to (?:a )?human|customer service|support agent)\\b\"]\n",
        "        },\n",
        "        \"risk_terms\": {\n",
        "            \"enabled\": True,\n",
        "            \"patterns\": [\"kyc\",\"blocked\",\"chargeback\",\"legal\",\"id verification\"]\n",
        "        },\n",
        "        \"bot_unhelpful_templates\": {\n",
        "            \"enabled\": True,\n",
        "            \"patterns\": [\n",
        "                \"could you provide more details\",\n",
        "                \"we could not find the information\",\n",
        "                \"check your spam folder\",\n",
        "                \"ensure your documents are clear and valid\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    \"llm\": {\"enabled\": False, \"max_latency_ms\": 400},\n",
        "    \"redis\": {\"ttl_seconds\": 86400}\n",
        "}\n",
        "\n",
        "def load_policy(path: str) -> Dict[str, Any]:\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"policy.yaml not found at {path}; using defaults and writing snapshot to artifacts.\")\n",
        "        with open(os.path.join(ARTIFACTS_DIR, \"policy.yaml\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            yaml.safe_dump(DEFAULT_POLICY, f, sort_keys=False, allow_unicode=True)\n",
        "        return DEFAULT_POLICY\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        p = yaml.safe_load(f) or {}\n",
        "    pol = DEFAULT_POLICY.copy()\n",
        "    pol.update(p)\n",
        "    with open(os.path.join(ARTIFACTS_DIR, \"policy.yaml\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(pol, f, sort_keys=False, allow_unicode=True)\n",
        "    return pol\n",
        "\n",
        "POLICY = load_policy(POLICY_PATH)\n",
        "RULES = POLICY.get(\"rules\", {})\n",
        "print(\"Policy loaded. Explicit patterns:\", RULES.get(\"explicit_human_request\", {}).get(\"patterns\", [])[:2], \"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 20 conversations.\n",
            "Sample IDs: ['c001', 'c002', 'c003', 'c004', 'c005']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === Load raw conversations and validate schema ===\n",
        "def load_conversations(path: str) -> List[Dict[str, Any]]:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Missing {path}. Put transcripts at data/escalation_dataset.json or set CONV_PATH.\"\n",
        "        )\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError(\"Root JSON must be a list of conversation objects.\")\n",
        "    if len(data) == 0:\n",
        "        raise ValueError(\"No conversations found.\")\n",
        "    for i, conv in enumerate(data[:5]):\n",
        "        assert \"conversation_id\" in conv, f\"conversation_id missing idx {i}\"\n",
        "        ch = conv.get(\"conversation_history\")\n",
        "        assert isinstance(ch, list), f\"conversation_history missing/not list idx {i}\"\n",
        "        assert all((\"role\" in m and \"message\" in m) for m in ch), f\"role/message missing idx {i}\"\n",
        "        assert \"is_escalation_needed\" in conv, f\"is_escalation_needed missing idx {i}\"\n",
        "    print(f\"Loaded {len(data)} conversations.\")\n",
        "    return data\n",
        "\n",
        "raw_conversations = load_conversations(DATA_PATH)\n",
        "print(\"Sample IDs:\", [c[\"conversation_id\"] for c in raw_conversations[:5]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turn-level dataset: (61, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>turn_global_idx</th>\n",
              "      <th>user_turn_idx</th>\n",
              "      <th>user_text</th>\n",
              "      <th>prev_bot_text</th>\n",
              "      <th>y</th>\n",
              "      <th>y_reason</th>\n",
              "      <th>is_escalation_needed_convo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c001</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I have tried to verify id for another sum up a...</td>\n",
              "      <td>Hello there. If you’d like to return to your p...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c001</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>So I resent and haven’t heard anything back</td>\n",
              "      <td>Okay, it seems there might be an issue with th...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c001</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>It’s been 2 weeks</td>\n",
              "      <td>Okay, verification may take a couple of days. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>fallback_last_user</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c002</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I’m not being sent a code to verify my device ...</td>\n",
              "      <td>Hello there! I'm here to assist you with anyth...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c002</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>I’ve done that</td>\n",
              "      <td>**Didn't get the code?**\\n\\n1. Tap **Resend co...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c002</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes all of that is good</td>\n",
              "      <td>Okay, let's try another approach. Ensure your ...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c002</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>Where will I find that</td>\n",
              "      <td>Got it. As a next step, try enabling **Push no...</td>\n",
              "      <td>1</td>\n",
              "      <td>fallback_last_user</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>c003</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hi I'm having issues with reports since the re...</td>\n",
              "      <td>Hello! If you'd like to return to our previous...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  conversation_id  turn_global_idx  user_turn_idx  \\\n",
              "0            c001                1              0   \n",
              "1            c001                3              1   \n",
              "2            c001                5              2   \n",
              "3            c002                1              0   \n",
              "4            c002                3              1   \n",
              "5            c002                5              2   \n",
              "6            c002                7              3   \n",
              "7            c003                1              0   \n",
              "\n",
              "                                           user_text  \\\n",
              "0  I have tried to verify id for another sum up a...   \n",
              "1        So I resent and haven’t heard anything back   \n",
              "2                                  It’s been 2 weeks   \n",
              "3  I’m not being sent a code to verify my device ...   \n",
              "4                                     I’ve done that   \n",
              "5                            Yes all of that is good   \n",
              "6                             Where will I find that   \n",
              "7  Hi I'm having issues with reports since the re...   \n",
              "\n",
              "                                       prev_bot_text  y            y_reason  \\\n",
              "0  Hello there. If you’d like to return to your p...  0                       \n",
              "1  Okay, it seems there might be an issue with th...  0                       \n",
              "2  Okay, verification may take a couple of days. ...  1  fallback_last_user   \n",
              "3  Hello there! I'm here to assist you with anyth...  0                       \n",
              "4  **Didn't get the code?**\\n\\n1. Tap **Resend co...  0                       \n",
              "5  Okay, let's try another approach. Ensure your ...  0                       \n",
              "6  Got it. As a next step, try enabling **Push no...  1  fallback_last_user   \n",
              "7  Hello! If you'd like to return to our previous...  0                       \n",
              "\n",
              "   is_escalation_needed_convo  \n",
              "0                        True  \n",
              "1                        True  \n",
              "2                        True  \n",
              "3                        True  \n",
              "4                        True  \n",
              "5                        True  \n",
              "6                        True  \n",
              "7                        True  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label counts: {0: 49, 1: 12}\n",
            "Conversations: 20\n"
          ]
        }
      ],
      "source": [
        "# === Weak labeling: earliest escalation-worthy user turn ===\n",
        "EXPL_PATTS = RULES.get(\"explicit_human_request\", {}).get(\"patterns\",\n",
        "            [r\"\\b(human|agent|real person|talk to (?:a )?human|speak to (?:a )?human|customer service|support agent)\\b\"])\n",
        "UNHELP_PATTS = RULES.get(\"bot_unhelpful_templates\", {}).get(\"patterns\",\n",
        "              [\"could you provide more details\",\"we could not find the information\",\"check your spam folder\",\"ensure your documents are clear and valid\"])\n",
        "\n",
        "def _regex_any(patterns: List[str], text: str) -> bool:\n",
        "    t = (text or \"\").lower()\n",
        "    return any(re.search(p, t) for p in patterns)\n",
        "\n",
        "def is_unhelpful_bot(msg: str) -> bool:\n",
        "    return _regex_any(UNHELP_PATTS, msg)\n",
        "\n",
        "def explicit_human_request(msg: str) -> bool:\n",
        "    return _regex_any(EXPL_PATTS, msg)\n",
        "\n",
        "def user_repeats(prev_user_msg: str, this_user_msg: str, jaccard_threshold: float = 0.5) -> bool:\n",
        "    if not prev_user_msg:\n",
        "        return False\n",
        "    a = set(w for w in re.findall(r\"[A-Za-z']+\", prev_user_msg.lower()) if len(w) > 2)\n",
        "    b = set(w for w in re.findall(r\"[A-Za-z']+\", this_user_msg.lower()) if len(w) > 2)\n",
        "    if not a or not b:\n",
        "        return False\n",
        "    inter = len(a & b); denom = max(1, len(a | b))\n",
        "    return (inter / denom) >= jaccard_threshold\n",
        "\n",
        "def weak_label_conversation(conv: Dict[str, Any]) -> Tuple[List[int], List[str]]:\n",
        "    ch = conv[\"conversation_history\"]\n",
        "    is_pos = bool(conv.get(\"is_escalation_needed\", False))\n",
        "    pos_user_turn_idx = None\n",
        "    reason = None\n",
        "    loop_score = 0\n",
        "    prev_user_text = \"\"\n",
        "\n",
        "    for idx, m in enumerate(ch):\n",
        "        role = m.get(\"role\"); text = m.get(\"message\", \"\") or \"\"\n",
        "        if role == \"user\" and explicit_human_request(text):\n",
        "            pos_user_turn_idx = idx; reason = \"explicit_request\"; break\n",
        "        if role == \"bot\" and is_unhelpful_bot(text):\n",
        "            loop_score += 1\n",
        "        if role == \"user\" and user_repeats(prev_user_text, text, 0.5):\n",
        "            loop_score += 1\n",
        "        if role == \"user\":\n",
        "            prev_user_text = text\n",
        "        if loop_score >= 2 and is_pos and pos_user_turn_idx is None:\n",
        "            if role == \"user\":\n",
        "                pos_user_turn_idx = idx\n",
        "            else:\n",
        "                for j in range(idx + 1, len(ch)):\n",
        "                    if ch[j][\"role\"] == \"user\":\n",
        "                        pos_user_turn_idx = j; break\n",
        "            reason = \"loop_unhelpful\"\n",
        "            if pos_user_turn_idx is not None:\n",
        "                break\n",
        "\n",
        "    if is_pos and pos_user_turn_idx is None:\n",
        "        for j in range(len(ch)-1, -1, -1):\n",
        "            if ch[j][\"role\"] == \"user\":\n",
        "                pos_user_turn_idx = j; reason = \"fallback_last_user\"; break\n",
        "\n",
        "    labels, reasons = [], []\n",
        "    for idx, m in enumerate(ch):\n",
        "        if m[\"role\"] != \"user\":\n",
        "            continue\n",
        "        if not is_pos:\n",
        "            labels.append(0); reasons.append(\"\")\n",
        "        else:\n",
        "            y = 1 if (pos_user_turn_idx is not None and idx >= pos_user_turn_idx) else 0\n",
        "            labels.append(y); reasons.append(reason if y==1 else \"\")\n",
        "    return labels, reasons\n",
        "\n",
        "def to_turn_rows(conv: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    rows = []\n",
        "    ch = conv[\"conversation_history\"]\n",
        "    labels, reasons = weak_label_conversation(conv)\n",
        "    user_turn_ptr = 0; prev_bot_msg = \"\"\n",
        "\n",
        "    for idx, m in enumerate(ch):\n",
        "        role = m[\"role\"]; msg = m.get(\"message\", \"\") or \"\"\n",
        "        if role == \"user\":\n",
        "            rows.append({\n",
        "                \"conversation_id\": conv[\"conversation_id\"],\n",
        "                \"turn_global_idx\": idx,\n",
        "                \"user_turn_idx\": user_turn_ptr,\n",
        "                \"user_text\": msg,\n",
        "                \"prev_bot_text\": prev_bot_msg,\n",
        "                \"y\": labels[user_turn_ptr],\n",
        "                \"y_reason\": reasons[user_turn_ptr],\n",
        "                \"is_escalation_needed_convo\": bool(conv.get(\"is_escalation_needed\", False)),\n",
        "            })\n",
        "            user_turn_ptr += 1\n",
        "        elif role == \"bot\":\n",
        "            prev_bot_msg = msg\n",
        "    return rows\n",
        "\n",
        "all_rows: List[Dict[str, Any]] = []\n",
        "for conv in raw_conversations:\n",
        "    all_rows.extend(to_turn_rows(conv))\n",
        "\n",
        "df = pd.DataFrame(all_rows)\n",
        "print(\"Turn-level dataset:\", df.shape)\n",
        "display(df.head(8))\n",
        "print(\"Label counts:\", df[\"y\"].value_counts().to_dict())\n",
        "print(\"Conversations:\", df[\"conversation_id\"].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved (pyarrow) → artifacts/turn_level_dataset.parquet\n"
          ]
        }
      ],
      "source": [
        "# === Save turn-level dataset ===\n",
        "parquet_path = os.path.join(ARTIFACTS_DIR, \"turn_level_dataset.parquet\")\n",
        "csv_path = os.path.join(ARTIFACTS_DIR, \"turn_level_dataset.csv\")\n",
        "\n",
        "dtype_map = {\n",
        "    \"conversation_id\": \"string\", \"turn_global_idx\": \"int32\", \"user_turn_idx\": \"int32\",\n",
        "    \"user_text\": \"string\", \"prev_bot_text\": \"string\", \"y\": \"int8\",\n",
        "    \"y_reason\": \"string\", \"is_escalation_needed_convo\": \"int8\"\n",
        "}\n",
        "df_out = df.astype(dtype_map)\n",
        "\n",
        "def save_with_fallbacks(df_out, parquet_path, csv_path):\n",
        "    try:\n",
        "        import pyarrow  # noqa\n",
        "        df_out.to_parquet(parquet_path, index=False, engine=\"pyarrow\")\n",
        "        print(f\"Saved (pyarrow) → {parquet_path}\")\n",
        "        return parquet_path\n",
        "    except Exception as e1:\n",
        "        print(\"pyarrow failed:\", e1)\n",
        "        try:\n",
        "            import fastparquet  # noqa\n",
        "            df_out.to_parquet(parquet_path, index=False, engine=\"fastparquet\")\n",
        "            print(f\"Saved (fastparquet) → {parquet_path}\")\n",
        "            return parquet_path\n",
        "        except Exception as e2:\n",
        "            print(\"fastparquet failed:\", e2)\n",
        "            df_out.to_csv(csv_path, index=False)\n",
        "            print(f\"Saved (CSV) → {csv_path}\")\n",
        "            return csv_path\n",
        "\n",
        "saved_turns_path = save_with_fallbacks(df_out, parquet_path, csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (61, 9) | Pos rate: 0.197\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>turn_idx</th>\n",
              "      <th>user_caps_ratio</th>\n",
              "      <th>exclam_count</th>\n",
              "      <th>msg_len</th>\n",
              "      <th>bot_unhelpful</th>\n",
              "      <th>user_requests_human</th>\n",
              "      <th>risk_terms</th>\n",
              "      <th>no_progress_count</th>\n",
              "      <th>bot_repeat_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   turn_idx  user_caps_ratio  exclam_count  msg_len  bot_unhelpful  \\\n",
              "0       0.0         0.030303           0.0    250.0            0.0   \n",
              "1       1.0         0.057143           0.0     43.0            0.0   \n",
              "2       2.0         0.083333           0.0     17.0            1.0   \n",
              "3       0.0         0.038462           0.0     99.0            0.0   \n",
              "4       1.0         0.090909           0.0     14.0            0.0   \n",
              "5       2.0         0.055556           0.0     23.0            0.0   \n",
              "\n",
              "   user_requests_human  risk_terms  no_progress_count  bot_repeat_count  \n",
              "0                  0.0         0.0                0.0               0.0  \n",
              "1                  0.0         0.0                0.0               0.0  \n",
              "2                  0.0         0.0                1.0               0.0  \n",
              "3                  0.0         0.0                0.0               0.0  \n",
              "4                  0.0         0.0                0.0               0.0  \n",
              "5                  0.0         0.0                0.0               0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# === Feature engineering (aligned with serving) ===\n",
        "UNHELPFUL_BOT_PATTERNS = RULES.get(\"bot_unhelpful_templates\", {}).get(\"patterns\",\n",
        "    [\"could you provide more details\",\"we could not find the information\",\"check your spam folder\",\"ensure your documents are clear and valid\"])\n",
        "HUMAN_REQUEST_PATTERNS = RULES.get(\"explicit_human_request\", {}).get(\"patterns\",\n",
        "    [r\"\\b(human|agent|real person|talk to (?:a )?human|speak to (?:a )?human|customer service|support agent)\\b\"])\n",
        "RISK_TERMS = RULES.get(\"risk_terms\", {}).get(\"patterns\", [\"kyc\",\"blocked\",\"chargeback\",\"legal\",\"id verification\"])\n",
        "\n",
        "def _has_any(patterns, s: str) -> int:\n",
        "    s = (s or \"\").lower()\n",
        "    return int(any(re.search(p, s) for p in patterns))\n",
        "\n",
        "def _caps_ratio(s: str) -> float:\n",
        "    if not s: return 0.0\n",
        "    caps = sum(1 for c in s if c.isupper())\n",
        "    letters = sum(1 for c in s if c.isalpha())\n",
        "    return (caps / letters) if letters else 0.0\n",
        "\n",
        "def _exclam_count(s: str) -> int:\n",
        "    return (s or \"\").count(\"!\")\n",
        "\n",
        "def _msg_len(s: str) -> int:\n",
        "    return len(s or \"\")\n",
        "\n",
        "def featurize(df_in: pd.DataFrame) -> pd.DataFrame:\n",
        "    X = pd.DataFrame({\n",
        "        \"turn_idx\": df_in[\"user_turn_idx\"].astype(float),\n",
        "        \"user_caps_ratio\": df_in[\"user_text\"].fillna(\"\").apply(_caps_ratio).astype(float),\n",
        "        \"exclam_count\": df_in[\"user_text\"].fillna(\"\").apply(_exclam_count).astype(float),\n",
        "        \"msg_len\": df_in[\"user_text\"].fillna(\"\").apply(_msg_len).astype(float),\n",
        "        \"bot_unhelpful\": df_in[\"prev_bot_text\"].fillna(\"\").apply(lambda s: _has_any(UNHELPFUL_BOT_PATTERNS, s)).astype(float),\n",
        "        \"user_requests_human\": df_in[\"user_text\"].fillna(\"\").apply(lambda s: _has_any(HUMAN_REQUEST_PATTERNS, s)).astype(float),\n",
        "        \"risk_terms\": df_in[\"user_text\"].fillna(\"\").apply(lambda s: _has_any(RISK_TERMS, s)).astype(float),\n",
        "    }, index=df_in.index)\n",
        "\n",
        "    X[\"no_progress_count\"] = 0.0\n",
        "    X[\"bot_repeat_count\"] = 0.0\n",
        "\n",
        "    for cid, idxs in df_in.groupby(\"conversation_id\").groups.items():\n",
        "        idxs = list(sorted(idxs, key=lambda i: (int(df_in.loc[i, \"user_turn_idx\"]), int(df_in.loc[i, \"turn_global_idx\"]))))\n",
        "        prev_bot = None; npc = 0; brc = 0\n",
        "        for i in idxs:\n",
        "            this_bot = (df_in.loc[i, \"prev_bot_text\"] or \"\").strip().lower()\n",
        "            if prev_bot and this_bot and (this_bot == prev_bot):\n",
        "                brc += 1\n",
        "            else:\n",
        "                brc = max(brc - 1, 0)\n",
        "            if _has_any(UNHELPFUL_BOT_PATTERNS, this_bot):\n",
        "                npc += 1\n",
        "            else:\n",
        "                npc = max(npc - 1, 0)\n",
        "            X.at[i, \"bot_repeat_count\"] = float(brc)\n",
        "            X.at[i, \"no_progress_count\"] = float(npc)\n",
        "            prev_bot = this_bot\n",
        "\n",
        "    return X.astype(float)\n",
        "\n",
        "X = featurize(df)\n",
        "y = df[\"y\"].astype(int).values\n",
        "groups = df[\"conversation_id\"].astype(\"string\").values\n",
        "\n",
        "FEATURE_ORDER = [\n",
        "    \"turn_idx\",\"user_caps_ratio\",\"exclam_count\",\"msg_len\",\n",
        "    \"bot_unhelpful\",\"user_requests_human\",\"risk_terms\",\n",
        "    \"no_progress_count\",\"bot_repeat_count\"\n",
        "]\n",
        "with open(os.path.join(ARTIFACTS_DIR, \"feature_order.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(FEATURE_ORDER, f, indent=2)\n",
        "\n",
        "print(\"X shape:\", X.shape, \"| Pos rate:\", round(float(y.mean()), 3))\n",
        "display(X.head(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (49, 9) | Test: (12, 9)\n",
            "Pos rate train: 0.204 | test: 0.167\n"
          ]
        }
      ],
      "source": [
        "# === Group-aware split ===\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
        "(train_idx, test_idx) = list(gss.split(X, y, groups))[0]\n",
        "\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y[train_idx], y[test_idx]\n",
        "groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
        "df_test = df.iloc[test_idx][[\"conversation_id\",\"user_turn_idx\",\"y\"]].copy()\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
        "print(\"Pos rate train:\", round(float(y_train.mean()), 3), \"| test:\", round(float(y_test.mean()), 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Metrics & threshold helpers ===\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "\n",
        "def pick_threshold_tpr_bound(y_true: np.ndarray, proba: np.ndarray, min_tpr: float = 0.90) -> float:\n",
        "    prec, rec, thr = precision_recall_curve(y_true, proba)\n",
        "    idxs = np.where(rec >= min_tpr)[0]\n",
        "    if len(idxs) >= 1 and len(thr) > 0:\n",
        "        candidate_thr = [thr[i-1] for i in idxs if i-1 >= 0]\n",
        "        if candidate_thr:\n",
        "            return float(min(candidate_thr))\n",
        "    f1 = (2 * prec * rec) / (prec + rec + 1e-9)\n",
        "    best_idx = int(np.nanargmax(f1))\n",
        "    tau = thr[max(0, best_idx - 1)] if len(thr) > 0 else 0.5\n",
        "    return float(tau)\n",
        "\n",
        "def early_escalation_at_first(df_test: pd.DataFrame, proba: np.ndarray, tau: float) -> float:\n",
        "    tmp = df_test.copy()\n",
        "    tmp = tmp.assign(proba=proba, pred=(proba >= tau).astype(int))\n",
        "    convs = tmp[\"conversation_id\"].unique()\n",
        "    total_pos, good = 0, 0\n",
        "    for cid in convs:\n",
        "        seq = tmp[tmp[\"conversation_id\"] == cid].sort_values(\"user_turn_idx\")\n",
        "        if seq[\"y\"].max() == 0:\n",
        "            continue\n",
        "        total_pos += 1\n",
        "        first_pos = int(seq[seq[\"y\"] == 1][\"user_turn_idx\"].min())\n",
        "        fired = seq[seq[\"user_turn_idx\"] <= first_pos][\"pred\"].max() == 1\n",
        "        if fired:\n",
        "            good += 1\n",
        "    return (good / total_pos) if total_pos else np.nan\n",
        "\n",
        "def premature_escalation_rate(df_test: pd.DataFrame, proba: np.ndarray, tau: float) -> float:\n",
        "    tmp = df_test.copy()\n",
        "    tmp = tmp.assign(proba=proba, pred=(proba >= tau).astype(int))\n",
        "    convs = tmp[\"conversation_id\"].unique()\n",
        "    total_pos, early = 0, 0\n",
        "    for cid in convs:\n",
        "        seq = tmp[tmp[\"conversation_id\"] == cid].sort_values(\"user_turn_idx\")\n",
        "        if seq[\"y\"].max() == 0:\n",
        "            continue\n",
        "        total_pos += 1\n",
        "        first_pos = int(seq[seq[\"y\"] == 1][\"user_turn_idx\"].min())\n",
        "        early_fire = seq[seq[\"user_turn_idx\"] < first_pos][\"pred\"].max() == 1\n",
        "        if early_fire:\n",
        "            early += 1\n",
        "    return (early / total_pos) if total_pos else np.nan\n",
        "\n",
        "def time_to_escalation_turns(df_test: pd.DataFrame, proba: np.ndarray, tau: float) -> float:\n",
        "    tmp = df_test.copy()\n",
        "    tmp = tmp.assign(proba=proba, pred=(proba >= tau).astype(int))\n",
        "    convs = tmp[\"conversation_id\"].unique()\n",
        "    diffs = []\n",
        "    for cid in convs:\n",
        "        seq = tmp[tmp[\"conversation_id\"] == cid].sort_values(\"user_turn_idx\")\n",
        "        if seq[\"y\"].max() == 0:\n",
        "            continue\n",
        "        first_pos = int(seq[seq[\"y\"] == 1][\"user_turn_idx\"].min())\n",
        "        pred_idxs = seq[seq[\"pred\"] == 1][\"user_turn_idx\"].values\n",
        "        if len(pred_idxs) == 0:\n",
        "            continue\n",
        "        first_pred = int(pred_idxs[0])\n",
        "        diffs.append(first_pred - first_pos)\n",
        "    return float(np.mean(diffs)) if diffs else np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:20:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/09/22 00:20:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>params</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>pr_auc</th>\n",
              "      <th>tau</th>\n",
              "      <th>ee_at_first</th>\n",
              "      <th>premature_rate</th>\n",
              "      <th>tte_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logreg</td>\n",
              "      <td>{'C': 0.5}</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.460922</td>\n",
              "      <td>0.081290</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>logreg</td>\n",
              "      <td>{'C': 2.0}</td>\n",
              "      <td>0.671795</td>\n",
              "      <td>0.443847</td>\n",
              "      <td>0.075093</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>logreg</td>\n",
              "      <td>{'C': 1.0}</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.426470</td>\n",
              "      <td>0.078844</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rf</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': None}</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.416053</td>\n",
              "      <td>0.093678</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rf</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 8}</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.416053</td>\n",
              "      <td>0.093678</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rf</td>\n",
              "      <td>{'n_estimators': 400, 'max_depth': None}</td>\n",
              "      <td>0.694872</td>\n",
              "      <td>0.401695</td>\n",
              "      <td>0.095351</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>rf</td>\n",
              "      <td>{'n_estimators': 400, 'max_depth': 8}</td>\n",
              "      <td>0.694872</td>\n",
              "      <td>0.401695</td>\n",
              "      <td>0.095351</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xgb</td>\n",
              "      <td>{'n_estimators': 300, 'max_depth': 4, 'learnin...</td>\n",
              "      <td>0.462821</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.107292</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xgb</td>\n",
              "      <td>{'n_estimators': 300, 'max_depth': 6, 'learnin...</td>\n",
              "      <td>0.462821</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.107292</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>xgb</td>\n",
              "      <td>{'n_estimators': 300, 'max_depth': 4, 'learnin...</td>\n",
              "      <td>0.462821</td>\n",
              "      <td>0.257526</td>\n",
              "      <td>0.104014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>-2.818182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    model                                             params   roc_auc  \\\n",
              "0  logreg                                         {'C': 0.5}  0.633333   \n",
              "1  logreg                                         {'C': 2.0}  0.671795   \n",
              "2  logreg                                         {'C': 1.0}  0.641026   \n",
              "3      rf           {'n_estimators': 200, 'max_depth': None}  0.705128   \n",
              "4      rf              {'n_estimators': 200, 'max_depth': 8}  0.705128   \n",
              "5      rf           {'n_estimators': 400, 'max_depth': None}  0.694872   \n",
              "6      rf              {'n_estimators': 400, 'max_depth': 8}  0.694872   \n",
              "7     xgb  {'n_estimators': 300, 'max_depth': 4, 'learnin...  0.462821   \n",
              "8     xgb  {'n_estimators': 300, 'max_depth': 6, 'learnin...  0.462821   \n",
              "9     xgb  {'n_estimators': 300, 'max_depth': 4, 'learnin...  0.462821   \n",
              "\n",
              "     pr_auc       tau  ee_at_first  premature_rate  tte_mean  \n",
              "0  0.460922  0.081290          1.0        0.909091 -2.818182  \n",
              "1  0.443847  0.075093          1.0        0.909091 -2.818182  \n",
              "2  0.426470  0.078844          1.0        0.909091 -2.818182  \n",
              "3  0.416053  0.093678          1.0        0.909091 -2.818182  \n",
              "4  0.416053  0.093678          1.0        0.909091 -2.818182  \n",
              "5  0.401695  0.095351          1.0        0.909091 -2.818182  \n",
              "6  0.401695  0.095351          1.0        0.909091 -2.818182  \n",
              "7  0.258824  0.107292          1.0        0.909091 -2.818182  \n",
              "8  0.258824  0.107292          1.0        0.909091 -2.818182  \n",
              "9  0.257526  0.104014          1.0        0.909091 -2.818182  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: logreg {'C': 0.5} {'roc_auc': 0.6333333333333333, 'pr_auc': 0.460921729156779, 'tau': 0.0812895078611868, 'ee_at_first': 1.0, 'premature_rate': 0.9090909090909091, 'tte_mean': -2.8181818181818183}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === Grouped CV + calibration + MLflow ===\n",
        "from itertools import product\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def cv_eval_config(name, estimator, params, X, y, groups, min_tpr=0.90, k=5, calibrate=True):\n",
        "    gkf = GroupKFold(n_splits=min(k, len(np.unique(groups))))\n",
        "    oof_proba, oof_truth, oof_meta = [], [], []\n",
        "\n",
        "    for fold, (tr, va) in enumerate(gkf.split(X, y, groups)):\n",
        "        est = estimator.set_params(**params)\n",
        "        if calibrate:\n",
        "            try:\n",
        "                clf = CalibratedClassifierCV(est, cv=3, method=\"sigmoid\")\n",
        "                clf.fit(X.iloc[tr], y[tr])\n",
        "            except Exception:\n",
        "                est.fit(X.iloc[tr], y[tr])\n",
        "                clf = CalibratedClassifierCV(est, cv=\"prefit\", method=\"sigmoid\")\n",
        "                clf.fit(X.iloc[tr], y[tr])\n",
        "        else:\n",
        "            est.fit(X.iloc[tr], y[tr])\n",
        "            clf = est\n",
        "        proba = clf.predict_proba(X.iloc[va])[:, 1]\n",
        "        oof_proba.append(proba); oof_truth.append(y[va])\n",
        "        oof_meta.append(df.iloc[va][[\"conversation_id\",\"user_turn_idx\",\"y\"]].copy())\n",
        "\n",
        "    proba_all = np.concatenate(oof_proba)\n",
        "    y_all = np.concatenate(oof_truth)\n",
        "    df_meta = pd.concat(oof_meta, axis=0)\n",
        "\n",
        "    roc = roc_auc_score(y_all, proba_all)\n",
        "    pr  = average_precision_score(y_all, proba_all)\n",
        "    tau = pick_threshold_tpr_bound(y_all, proba_all, min_tpr=min_tpr)\n",
        "    ee  = early_escalation_at_first(df_meta, proba_all, tau)\n",
        "    per = premature_escalation_rate(df_meta, proba_all, tau)\n",
        "    tte = time_to_escalation_turns(df_meta, proba_all, tau)\n",
        "\n",
        "    est_full = estimator.set_params(**params)\n",
        "    if calibrate:\n",
        "        try:\n",
        "            clf_full = CalibratedClassifierCV(est_full, cv=3, method=\"sigmoid\")\n",
        "            clf_full.fit(X, y)\n",
        "        except Exception:\n",
        "            est_full.fit(X, y)\n",
        "            clf_full = CalibratedClassifierCV(est_full, cv=\"prefit\", method=\"sigmoid\")\n",
        "            clf_full.fit(X, y)\n",
        "    else:\n",
        "        est_full.fit(X, y)\n",
        "        clf_full = est_full\n",
        "\n",
        "    metrics = {\n",
        "        \"roc_auc\": float(roc),\n",
        "        \"pr_auc\": float(pr),\n",
        "        \"tau\": float(tau),\n",
        "        \"ee_at_first\": float(ee),\n",
        "        \"premature_rate\": float(per),\n",
        "        \"tte_mean\": float(tte),\n",
        "    }\n",
        "    return clf_full, tau, metrics\n",
        "\n",
        "# Candidate grids\n",
        "grids = [\n",
        "    (\"logreg\", LogisticRegression(class_weight=\"balanced\", max_iter=2000, solver=\"liblinear\"),\n",
        "     {\"C\": [0.5, 1.0, 2.0]}, True),\n",
        "    (\"rf\", RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=SEED, n_jobs=-1),\n",
        "     {\"n_estimators\": [200, 400], \"max_depth\": [None, 8]}, True),\n",
        "]\n",
        "\n",
        "# Optional XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    grids.append((\"xgb\",\n",
        "        xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
        "                          tree_method=\"hist\", n_jobs=-1, random_state=SEED),\n",
        "        {\"n_estimators\":[300,500], \"max_depth\":[4,6], \"learning_rate\":[0.05,0.1]},\n",
        "        True))\n",
        "except Exception as e:\n",
        "    print(\"XGBoost not available for CV:\", e)\n",
        "\n",
        "MIN_TPR = float(os.getenv(\"MIN_TPR\", \"0.90\"))\n",
        "K_FOLDS = int(os.getenv(\"K_FOLDS\", \"5\"))\n",
        "\n",
        "cv_results = []\n",
        "best = None\n",
        "best_key = (-np.inf, -np.inf, -np.inf)\n",
        "\n",
        "for name, est, grid, calibrate in grids:\n",
        "    keys, values = zip(*grid.items())\n",
        "    for combo in product(*values):\n",
        "        params = dict(zip(keys, combo))\n",
        "        with mlflow.start_run(run_name=f\"{name}_cv_{params}\"):\n",
        "            mlflow.log_params({\"model\": name, **params, \"cv_k\": K_FOLDS, \"min_tpr\": MIN_TPR, \"calibrate\": calibrate})\n",
        "            clf_full, tau, metrics = cv_eval_config(\n",
        "                name, est, params, X_train, y_train, groups_train, min_tpr=MIN_TPR, k=K_FOLDS, calibrate=calibrate\n",
        "            )\n",
        "            mlflow.log_metrics({\n",
        "                \"cv_roc_auc\": metrics[\"roc_auc\"],\n",
        "                \"cv_pr_auc\": metrics[\"pr_auc\"],\n",
        "                \"cv_tau\": metrics[\"tau\"],\n",
        "                \"cv_ee_first\": metrics[\"ee_at_first\"],\n",
        "                \"cv_premature_rate\": metrics[\"premature_rate\"],\n",
        "                \"cv_tte_mean\": metrics[\"tte_mean\"],\n",
        "            })\n",
        "            tmp_path = os.path.join(ARTIFACTS_DIR, f\"{name}_{int(time.time())}.joblib\")\n",
        "            joblib.dump(clf_full, tmp_path)\n",
        "            mlflow.sklearn.log_model(clf_full, artifact_path=\"model\", input_example=X_test.iloc[:5])\n",
        "\n",
        "            row = {\"model\": name, \"params\": params, **metrics}\n",
        "            cv_results.append(row)\n",
        "\n",
        "            key = (metrics[\"ee_at_first\"], metrics[\"pr_auc\"], metrics[\"roc_auc\"])\n",
        "            if key > best_key or (np.isnan(best_key[0]) and not np.isnan(key[0])):\n",
        "                best, best_key = (clf_full, tau, name, params, metrics), key\n",
        "\n",
        "summary = pd.DataFrame(cv_results).sort_values(\n",
        "    by=[\"ee_at_first\",\"pr_auc\",\"roc_auc\"], ascending=[False, False, False]\n",
        ").reset_index(drop=True)\n",
        "display(summary.head(10))\n",
        "\n",
        "best_clf, best_tau, best_name, best_params, best_metrics = best\n",
        "print(\"Best:\", best_name, best_params, best_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/22 00:21:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST — ROC-AUC=0.950 PR-AUC=0.833 EE@first=1.000 Premature=1.000 TTE_mean=-1.500 tau=0.081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mukeshsingh/Desktop/sumup/venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promoted model → artifacts/model.joblib\n",
            "Wrote metadata → artifacts/version.txt\n",
            "Also wrote feature_order.json and policy.yaml snapshot in artifacts/.\n"
          ]
        }
      ],
      "source": [
        "# === Final test-set evaluation & promotion ===\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "proba_test = best_clf.predict_proba(X_test)[:, 1]\n",
        "roc = roc_auc_score(y_test, proba_test)\n",
        "pr  = average_precision_score(y_test, proba_test)\n",
        "\n",
        "tau = float(best_tau)\n",
        "ee  = early_escalation_at_first(df_test, proba_test, tau)\n",
        "per = premature_escalation_rate(df_test, proba_test, tau)\n",
        "tte = time_to_escalation_turns(df_test, proba_test, tau)\n",
        "\n",
        "print(f\"TEST — ROC-AUC={roc:.3f} PR-AUC={pr:.3f} EE@first={ee:.3f} Premature={per:.3f} TTE_mean={tte:.3f} tau={tau:.3f}\")\n",
        "\n",
        "with mlflow.start_run(run_name=f\"final_test_{best_name}_{best_params}\"):\n",
        "    mlflow.log_params({\"final_model\": best_name, **best_params, \"tau\": tau})\n",
        "    mlflow.log_metrics({\n",
        "        \"test_roc_auc\": float(roc),\n",
        "        \"test_pr_auc\": float(pr),\n",
        "        \"test_ee_first\": float(ee),\n",
        "        \"test_premature_rate\": float(per),\n",
        "        \"test_tte_mean\": float(tte),\n",
        "    })\n",
        "    mlflow.sklearn.log_model(best_clf, artifact_path=\"model\", input_example=X_test.iloc[:5])\n",
        "\n",
        "model_path = os.path.join(ARTIFACTS_DIR, \"model.joblib\")\n",
        "joblib.dump(best_clf, model_path)\n",
        "\n",
        "version_txt = os.path.join(ARTIFACTS_DIR, \"version.txt\")\n",
        "with open(version_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\n",
        "        f\"{best_name}@{int(time.time())}\\n\"\n",
        "        f\"params={best_params}\\n\"\n",
        "        f\"threshold={tau}\\n\"\n",
        "        f\"test_roc_auc={roc:.4f}\\n\"\n",
        "        f\"test_pr_auc={pr:.4f}\\n\"\n",
        "        f\"test_ee_first={ee:.4f}\\n\"\n",
        "        f\"test_premature_rate={per:.4f}\\n\"\n",
        "        f\"test_tte_mean={tte:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "print(\"Promoted model →\", model_path)\n",
        "print(\"Wrote metadata →\", version_txt)\n",
        "print(\"Also wrote feature_order.json and policy.yaml snapshot in artifacts/.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
